{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auther: Tzu-Han Hsu\n",
    "\n",
    "# BSD 3-Clause License\n",
    "\n",
    "# Copyright (c) 2022, Anywhere Door Lab (ADL) and Tzu-Han Hsu\n",
    "# All rights reserved.\n",
    "\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "# 1. Redistributions of source code must retain the above copyright notice, this\n",
    "#    list of conditions and the following disclaimer.\n",
    "\n",
    "# 2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "#    this list of conditions and the following disclaimer in the documentation\n",
    "#    and/or other materials provided with the distribution.\n",
    "\n",
    "# 3. Neither the name of the copyright holder nor the names of its\n",
    "#    contributors may be used to endorse or promote products derived from\n",
    "#    this software without specific prior written permission.\n",
    "\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db038553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AlexNet_stn2 with 10 classes running on: cifar10\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import os\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import torchvision.datasets as dset\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from torchsummary import summary\n",
    "\n",
    "#vital params\n",
    "\n",
    " \n",
    "model_name=\"AlexNet_stn2\"\n",
    "\n",
    "dataset_name=\"cifar10\"\n",
    "\n",
    "#hyperparameters\n",
    "batch_size=20\n",
    "num_classes=-1\n",
    "learning_rate=0.001\n",
    "input_size=784\n",
    "image_size=(224,224)\n",
    "\n",
    "\n",
    "if dataset_name == \"tsrd\":\n",
    "    num_classes=58\n",
    "elif dataset_name == \"cifar10\":\n",
    "    num_classes=10\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Model: \"+model_name +\" with {} classes\".format(num_classes)+\n",
    "      \" running on: \"+dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38958e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset size: Train: 40000, Valid: 10000, Test: 10000\n",
      "torch.Size([3, 224, 224])\n",
      "Datasets loaded and prepared\n"
     ]
    }
   ],
   "source": [
    "# load data through imagefolder\n",
    "if dataset_name == \"tsrd\":\n",
    "    main_transforms=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406] , std = [0.229, 0.224, 0.225]),\n",
    "\n",
    "    ])\n",
    "\n",
    "    train_dir = \"../../dataset/data\"\n",
    "    head_train_set = dset.ImageFolder(train_dir,transform=main_transforms)\n",
    "    train_set, valid_set = data.random_split(head_train_set, [5000, 998])\n",
    "    train_set, test_set = data.random_split(train_set,[4000, 1000])\n",
    "\n",
    "\n",
    "    train_dataloader=torch.utils.data.DataLoader(train_set,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=True)\n",
    "\n",
    "    val_dataloader=torch.utils.data.DataLoader(valid_set,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=True)\n",
    "\n",
    "    test_dataloader=torch.utils.data.DataLoader(test_set,\n",
    "                                                 batch_size=1,\n",
    "                                                 shuffle=True)\n",
    "    print(head_train_set.class_to_idx)\n",
    "elif dataset_name == \"cifar10\":\n",
    "    \n",
    "    main_transforms=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.5, 0.5, 0.5] , std = [0.5, 0.5, 0.5]),\n",
    "\n",
    "    ])\n",
    "\n",
    "    bigtrain_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=main_transforms)\n",
    "    train_set, valid_set = data.random_split(bigtrain_set, [40000, 10000])\n",
    "    test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=main_transforms)\n",
    "\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=True, num_workers=2)\n",
    "\n",
    "    val_dataloader = torch.utils.data.DataLoader(valid_set, \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=True, num_workers=2)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Dataset size: Train: {}, Valid: {}, Test: {}\"\n",
    "      .format(len(train_set),len(valid_set),len(test_set)))\n",
    "\n",
    "\n",
    "print(train_set[0][0].shape)\n",
    "print(\"Datasets loaded and prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f899891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3,4,kernel_size=3,stride = 2,padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(4,8,kernel_size=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,8,kernel_size=3,stride=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,4,kernel_size=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(4,8,kernel_size=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,8,kernel_size=3,stride=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,4,kernel_size=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(4,8,kernel_size=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,8,kernel_size=3,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,4,kernel_size=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(4,8,kernel_size=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,8,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,4,kernel_size=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(4,8,kernel_size=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,8,kernel_size=3,stride=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8,4,kernel_size=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv2d(4,10,kernel_size=1),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(27040, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "    def stn(self, x):    \n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(xs.shape[0], xs.shape[1]*xs.shape[2]*xs.shape[3])\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.stn(x)\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe94e559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 224, 224])\n",
      "torch.Size([20, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 4, 112, 112]             112\n",
      "       BatchNorm2d-2          [-1, 4, 112, 112]               8\n",
      "              ReLU-3          [-1, 4, 112, 112]               0\n",
      "            Conv2d-4          [-1, 8, 112, 112]              40\n",
      "       BatchNorm2d-5          [-1, 8, 112, 112]              16\n",
      "              ReLU-6          [-1, 8, 112, 112]               0\n",
      "            Conv2d-7          [-1, 8, 110, 110]             584\n",
      "       BatchNorm2d-8          [-1, 8, 110, 110]              16\n",
      "              ReLU-9          [-1, 8, 110, 110]               0\n",
      "           Conv2d-10          [-1, 4, 110, 110]              36\n",
      "      BatchNorm2d-11          [-1, 4, 110, 110]               8\n",
      "             ReLU-12          [-1, 4, 110, 110]               0\n",
      "           Conv2d-13          [-1, 8, 110, 110]              40\n",
      "      BatchNorm2d-14          [-1, 8, 110, 110]              16\n",
      "             ReLU-15          [-1, 8, 110, 110]               0\n",
      "           Conv2d-16          [-1, 8, 108, 108]             584\n",
      "      BatchNorm2d-17          [-1, 8, 108, 108]              16\n",
      "             ReLU-18          [-1, 8, 108, 108]               0\n",
      "           Conv2d-19          [-1, 4, 108, 108]              36\n",
      "      BatchNorm2d-20          [-1, 4, 108, 108]               8\n",
      "             ReLU-21          [-1, 4, 108, 108]               0\n",
      "           Conv2d-22          [-1, 8, 108, 108]              40\n",
      "      BatchNorm2d-23          [-1, 8, 108, 108]              16\n",
      "             ReLU-24          [-1, 8, 108, 108]               0\n",
      "           Conv2d-25            [-1, 8, 54, 54]             584\n",
      "      BatchNorm2d-26            [-1, 8, 54, 54]              16\n",
      "             ReLU-27            [-1, 8, 54, 54]               0\n",
      "           Conv2d-28            [-1, 4, 54, 54]              36\n",
      "      BatchNorm2d-29            [-1, 4, 54, 54]               8\n",
      "             ReLU-30            [-1, 4, 54, 54]               0\n",
      "           Conv2d-31            [-1, 8, 54, 54]              40\n",
      "      BatchNorm2d-32            [-1, 8, 54, 54]              16\n",
      "             ReLU-33            [-1, 8, 54, 54]               0\n",
      "           Conv2d-34            [-1, 8, 54, 54]             584\n",
      "      BatchNorm2d-35            [-1, 8, 54, 54]              16\n",
      "             ReLU-36            [-1, 8, 54, 54]               0\n",
      "           Conv2d-37            [-1, 4, 54, 54]              36\n",
      "      BatchNorm2d-38            [-1, 4, 54, 54]               8\n",
      "             ReLU-39            [-1, 4, 54, 54]               0\n",
      "           Conv2d-40            [-1, 8, 54, 54]              40\n",
      "      BatchNorm2d-41            [-1, 8, 54, 54]              16\n",
      "             ReLU-42            [-1, 8, 54, 54]               0\n",
      "           Conv2d-43            [-1, 8, 52, 52]             584\n",
      "      BatchNorm2d-44            [-1, 8, 52, 52]              16\n",
      "             ReLU-45            [-1, 8, 52, 52]               0\n",
      "           Conv2d-46            [-1, 4, 52, 52]              36\n",
      "      BatchNorm2d-47            [-1, 4, 52, 52]               8\n",
      "             ReLU-48            [-1, 4, 52, 52]               0\n",
      "           Conv2d-49           [-1, 10, 52, 52]              50\n",
      "      BatchNorm2d-50           [-1, 10, 52, 52]              20\n",
      "             ReLU-51           [-1, 10, 52, 52]               0\n",
      "           Linear-52                   [-1, 32]         865,312\n",
      "             ReLU-53                   [-1, 32]               0\n",
      "           Linear-54                    [-1, 6]             198\n",
      "           Conv2d-55           [-1, 64, 55, 55]          23,296\n",
      "             ReLU-56           [-1, 64, 55, 55]               0\n",
      "        MaxPool2d-57           [-1, 64, 27, 27]               0\n",
      "           Conv2d-58          [-1, 192, 27, 27]         307,392\n",
      "             ReLU-59          [-1, 192, 27, 27]               0\n",
      "        MaxPool2d-60          [-1, 192, 13, 13]               0\n",
      "           Conv2d-61          [-1, 384, 13, 13]         663,936\n",
      "             ReLU-62          [-1, 384, 13, 13]               0\n",
      "           Conv2d-63          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-64          [-1, 256, 13, 13]               0\n",
      "           Conv2d-65          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-66          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-67            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-68            [-1, 256, 6, 6]               0\n",
      "          Dropout-69                 [-1, 9216]               0\n",
      "           Linear-70                 [-1, 4096]      37,752,832\n",
      "             ReLU-71                 [-1, 4096]               0\n",
      "          Dropout-72                 [-1, 4096]               0\n",
      "           Linear-73                 [-1, 4096]      16,781,312\n",
      "             ReLU-74                 [-1, 4096]               0\n",
      "           Linear-75                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 57,914,010\n",
      "Trainable params: 57,914,010\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 26.73\n",
      "Params size (MB): 220.92\n",
      "Estimated Total Size (MB): 248.23\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "model shape ready\n",
      "model initialised\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet().to(device)\n",
    "\n",
    "#pretesting model for shape\n",
    "x=torch.randn(batch_size,3,224,224)\n",
    "x=x.to(device)\n",
    "print(x.shape)\n",
    "print(model(x).shape)\n",
    "print(summary(model, input_size=(3, 224, 224)))\n",
    "print(\"model shape ready\")\n",
    "\n",
    "#initailise network\n",
    "\n",
    "\n",
    "#loss and optimizer\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "print(\"model initialised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "592a8158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test defined\n",
      "early stop defined\n"
     ]
    }
   ],
   "source": [
    "# This is the testing part\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "get_n_params(model)\n",
    "\n",
    "def test(model, test_loader, istest= False, doprint=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad(): # disable gradient calculation for efficiency\n",
    "        for data, target in tqdm(test_loader):\n",
    "            # Prediction\n",
    "            data=data.to(device=device)\n",
    "            target=target.to(device=device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss=criterion(output,target)\n",
    "            \n",
    "            # Compute loss & accuracy\n",
    "            test_loss+=loss.item()*data.size(0)\n",
    "\n",
    "            \n",
    "            #test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() # how many predictions in this batch are correct\n",
    "            \n",
    "            #print(\"pred={} , target={} , judge={}\".format(pred.item(),target.item(),pred.eq(target.view_as(pred)).sum().item()))\n",
    "\n",
    "            \n",
    "    #test_loss /= len(test_loader.dataset)\n",
    "\n",
    "        \n",
    "    # Log testing info\n",
    "    if istest and doprint:\n",
    "        \n",
    "        print('Loss: {}   Accuracy: {}/{} ({:.0f}%)'.format(test_loss,\n",
    "        correct, len(test_loader.dataset),\n",
    "        100.000 * correct / len(test_loader.dataset)))\n",
    "        print(\"Total parameters: {}\".format(get_n_params(model)))\n",
    "    elif doprint:\n",
    "        print('Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100.00 * correct / len(test_loader.dataset)))\n",
    "    return 100.00 * correct / len(test_loader.dataset)\n",
    "        \n",
    "\n",
    "print(\"test defined\")\n",
    "\n",
    "def testshouldearlystop(acclist,minepoch,epochwindow,accwindow):\n",
    "    runlen=len(acclist)\n",
    "    if(runlen<minepoch):\n",
    "        return False\n",
    "    elif(acclist[-1]>acclist[-2]):\n",
    "        return False\n",
    "    \n",
    "    watchwindow=acclist[-epochwindow:]\n",
    "    shouldjump=True\n",
    "    sum=0\n",
    "    for i in watchwindow:\n",
    "        sum+=i\n",
    "    avg = sum/epochwindow\n",
    "    for i in watchwindow:\n",
    "        if abs(i-avg)>(accwindow):\n",
    "            shouldjump=False\n",
    "    return shouldjump\n",
    "print(\"early stop defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49606c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard_string:\n",
      "runs//AlexNet_stn220211125012347\n",
      "grandstore_string\n",
      "grandstore/cifar10_AlexNet_stn220211125012347.pkl\n"
     ]
    }
   ],
   "source": [
    "now=datetime.now()\n",
    "dt_string = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "tensorboard_string=\"runs/\"+\"/\"+model_name+dt_string\n",
    "grandstore_string=\"grandstore/\"+dataset_name+\"_\"+model_name+dt_string+\".pkl\"\n",
    "print(\"tensorboard_string:\")\n",
    "print(tensorboard_string)\n",
    "print(\"grandstore_string\")\n",
    "print(grandstore_string)\n",
    "\n",
    "\n",
    "writer = SummaryWriter(tensorboard_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3316dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the training part\n",
    "\n",
    "# Grand_store={\n",
    "#     'total_epoch_run':-1\n",
    "#     'topmodels':-1\n",
    "#     'lastmodel':-1\n",
    "#     'acclog':[]\n",
    "#     'maxacc':-1\n",
    "#     'minacc':101\n",
    "# }\n",
    "# train_epoch={\n",
    "#     \"numofepoch\":-1\n",
    "#     \"accuracy\":-1\n",
    "#     \"model_state\":model.state_dict(),\n",
    "#     \"optim_state\":optimizer.state_dict(),\n",
    "#     \"totaltrain_loss\":totaltrain_loss,\n",
    "#     \"totalvalid_loss\":totalvalid_loss\n",
    "# }\n",
    "\n",
    "def training(max_epoch=120, top_accuracy_track=3, grandstore={},\n",
    "             minepoch=30,epochwindow=10,accwindow=0.35):\n",
    "\n",
    "    grandstore['total_epoch_run']=0\n",
    "    grandstore['topmodels']=[]\n",
    "    grandstore['acclog']=[]\n",
    "    grandstore['maxacc']=-1\n",
    "    grandstore['minacc']=101\n",
    "    \n",
    "    for epoch in range(0,max_epoch):\n",
    "        \n",
    "        grandstore['total_epoch_run']=epoch+1\n",
    "        \n",
    "        train_epoch={\n",
    "        \"numofepoch\":grandstore['total_epoch_run']\n",
    "        }\n",
    "    \n",
    "        train_loss=0.0\n",
    "        valid_loss=0.0\n",
    "        print(\"Running epoch: {}\".format(epoch+1))\n",
    "\n",
    "        model.train()\n",
    "        totaltrain_loss=0\n",
    "        \n",
    "        #this is the training part\n",
    "        for data,target in tqdm(train_dataloader):\n",
    "            data=data.to(device=device)\n",
    "            target=target.to(device=device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            totaltrain_loss += train_loss\n",
    "\n",
    "        #this is the validation part\n",
    "        model.eval()\n",
    "        totalvalid_loss=0;\n",
    "        correct = 0\n",
    "        for data,target in tqdm(val_dataloader):\n",
    "            data=data.to(device=device)\n",
    "            target=target.to(device=device)\n",
    "            output=model(data)\n",
    "            loss=criterion(output,target)\n",
    "            valid_loss=loss.item()*data.size(0)\n",
    "            #train_loss = train_loss/len(train_dataloader.dataset)\n",
    "            #valid_loss = valid_loss/len(val_dataloader.dataset)\n",
    "            totalvalid_loss+=valid_loss\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() # how many predictions in t\n",
    "        \n",
    "\n",
    "        training_accuracy=100. * correct / len(val_dataloader.dataset)\n",
    "        train_epoch[\"accuracy\"]=training_accuracy\n",
    "        train_epoch[\"totaltrain_loss\"]=totaltrain_loss\n",
    "        train_epoch[\"totalvalid_loss\"]=totalvalid_loss\n",
    "        \n",
    "        #writings to the GrandStore\n",
    "        \n",
    "        grandstore['acclog'].append(training_accuracy)\n",
    "        \n",
    "        if training_accuracy < grandstore['minacc']:\n",
    "            grandstore['minacc'] = training_accuracy\n",
    "            \n",
    "        if training_accuracy > grandstore['maxacc']:\n",
    "            grandstore['maxacc'] = training_accuracy\n",
    "        \n",
    "\n",
    "        if epoch < top_accuracy_track:\n",
    "            thisepochtestresult=test(model,test_dataloader,istest = True,doprint=False)\n",
    "            grandstore['topmodels'].append((training_accuracy,thisepochtestresult,epoch+1,train_epoch))\n",
    "            #if error print this\n",
    "            grandstore['topmodels'].sort()\n",
    "\n",
    "        elif training_accuracy > grandstore['topmodels'][0][0]:\n",
    "            thisepochtestresult=test(model,test_dataloader,istest = True,doprint=False)\n",
    "            grandstore['topmodels'][0]=(training_accuracy,thisepochtestresult,epoch+1,train_epoch)\n",
    "            #if error print this\n",
    "            grandstore['topmodels'].sort()\n",
    "\n",
    "        if epoch == (max_epoch-1):\n",
    "            thisepochtestresult=test(model,test_dataloader,istest = True,doprint=False)\n",
    "            grandstore['lastmodel']=(training_accuracy,thisepochtestresult,epoch+1,train_epoch)\n",
    "                     \n",
    "        writer.add_scalar('Training Loss',totaltrain_loss,global_step = epoch)\n",
    "        writer.add_scalar('Valid Loss',totalvalid_loss,global_step = epoch)\n",
    "        writer.add_scalar('Accuracy',training_accuracy,global_step = epoch)\n",
    "        \n",
    "        print('Accuracy: {:.2f}'.format(training_accuracy))\n",
    "        print('Training Loss: {:.6f} \\tValidation Loss: {:.6f}\\n'.format(totaltrain_loss, totalvalid_loss))\n",
    "        \n",
    "        #early stopping criteria\n",
    "        if(testshouldearlystop(acclist=grandstore['acclog'],\n",
    "                               minepoch = minepoch,\n",
    "                               epochwindow = epochwindow,\n",
    "                               accwindow = accwindow)):\n",
    "            print(\"early stop occured!!\")\n",
    "            thisepochtestresult=test(model,test_dataloader,istest = True,doprint=False)\n",
    "            grandstore['lastmodel']=(training_accuracy,thisepochtestresult,epoch+1,train_epoch)\n",
    "            return grandstore\n",
    "    \n",
    "    return grandstore\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f494cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486f82cffa2148de98035f4b0aa35da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b477f031d94955bf58fae37a16b963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19554540e14c47ce9a47e06528bdcdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9.35\n",
      "Training Loss: 92205544.982858 \tValidation Loss: 23030.197430\n",
      "\n",
      "Running epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c7d88cfdc0459e90ab7513ba99f106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOP_ACCURACY_TRACK = 15\n",
    "# max_epoch=120, top_accuracy_track=3, grandstore={},\n",
    "# minepoch=30,epochwindow=10,accwindow=0.35\n",
    "\n",
    "Grandstore=training(max_epoch=360,\n",
    "                    minepoch=150,\n",
    "                    top_accuracy_track=TOP_ACCURACY_TRACK,\n",
    "                    epochwindow=10,\n",
    "                    accwindow=0.25                 \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4013c87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Run 120 epoch(s)\n",
      "Accuracy MIN: 36.98 / MAX: 64.14\n",
      "\n",
      "Top 5 performing epochs:\n",
      "#1 epoch 49\t||train_acc 64.14%\t||test63.73%\n",
      "#2 epoch 54\t||train_acc 63.57%\t||test63.63%\n",
      "#3 epoch 41\t||train_acc 63.39%\t||test62.8%\n",
      "#4 epoch 47\t||train_acc 63.27%\t||test62.92%\n",
      "#5 epoch 107\t||train_acc 63.23%\t||test62.31%\n",
      "\n",
      "Last epoch:\n",
      "epoch 120\t||train_acc 62.11%\t||test61.05%\n",
      "\n",
      "The model has parameters: 57913514\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Total Run {} epoch(s)\".format(Grandstore['total_epoch_run']))\n",
    "\n",
    "plt.plot(*[range(1,Grandstore['total_epoch_run']+1)],Grandstore['acclog'])\n",
    "print(\"Accuracy MIN: {} / MAX: {}\".format(Grandstore['minacc'],Grandstore['maxacc']))\n",
    "print()\n",
    "print(\"Top {} performing epochs:\".format(TOP_ACCURACY_TRACK))\n",
    "\n",
    "\n",
    "gstm=Grandstore['topmodels']\n",
    "for i in range(TOP_ACCURACY_TRACK):\n",
    "    easy=gstm[TOP_ACCURACY_TRACK-i-1]\n",
    "    print(\"#{} epoch {}\\t||train_acc {}%\\t||test{}%\".format(i+1,easy[2],easy[0],easy[1]))\n",
    "print()\n",
    "print(\"Last epoch:\")\n",
    "lsmd=Grandstore['lastmodel']\n",
    "print(\"epoch {}\\t||train_acc {}%\\t||test{}%\".format(Grandstore['total_epoch_run'],lsmd[0],lsmd[1]))\n",
    "      \n",
    "print()\n",
    "print(\"The model has parameters: {}\".format(get_n_params(model)))\n",
    "#grandstore['lastmodel']=((training_accuracy,train_epoch,thisepochtestresult))\n",
    "# grandstore['lastmodel']=(training_accuracy,thisepochtestresult,epoch+1,train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac30dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "f1=open(grandstore_string,\"wb\")\n",
    "pickle.dump(Grandstore,f1)\n",
    "f1.close()\n",
    "# with open(grandstore_string, 'rb') as file:\n",
    "#     myvar = pickle.load(file)\n",
    "#     print(myvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ddef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
